{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ed381c",
   "metadata": {
    "papermill": {
     "duration": 0.022496,
     "end_time": "2022-05-05T11:24:06.118995",
     "exception": false,
     "start_time": "2022-05-05T11:24:06.096499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The EfficentNet model\n",
    "\n",
    "Using effent because it should later run on edge AI device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d83ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:14.101280Z",
     "iopub.status.busy": "2022-05-05T11:24:14.100810Z",
     "iopub.status.idle": "2022-05-05T11:24:14.106190Z",
     "shell.execute_reply": "2022-05-05T11:24:14.105470Z"
    },
    "papermill": {
     "duration": 0.02918,
     "end_time": "2022-05-05T11:24:14.108133",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.078953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "Training_Percentage = 0.2           \n",
    "Epoch_Anz = 50\n",
    "nb_classes = 100                     # move to 1. step\n",
    "#input_shape = (32, 20,1)            # will be calculated\n",
    "Batch_Size = 32\n",
    "use_grayscale = True                # grayscale or rgb\n",
    "model_filename = \"eff100-gray.h5\"\n",
    "\n",
    "##########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01a329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:06.163318Z",
     "iopub.status.busy": "2022-05-05T11:24:06.162702Z",
     "iopub.status.idle": "2022-05-05T11:24:12.690226Z",
     "shell.execute_reply": "2022-05-05T11:24:12.689336Z"
    },
    "papermill": {
     "duration": 6.552535,
     "end_time": "2022-05-05T11:24:12.693311",
     "exception": false,
     "start_time": "2022-05-05T11:24:06.140776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.callbacks import *\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, Rescaling, LayerNormalization\n",
    "\n",
    "def get_post(x_in):\n",
    "    x = LeakyReLU()(x_in)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def get_block(x_in, ch_in, ch_out):\n",
    "    x = Conv2D(ch_in,\n",
    "               kernel_size=(1, 1),\n",
    "               padding='same',\n",
    "               use_bias=False)(x_in)\n",
    "    x = get_post(x)\n",
    "\n",
    "    x = DepthwiseConv2D(kernel_size=(1, 3), padding='same', use_bias=False)(x)\n",
    "    x = get_post(x)\n",
    "    x = MaxPool2D(pool_size=(2, 1),\n",
    "                  strides=(2, 1))(x) # Separable pooling\n",
    "\n",
    "    x = DepthwiseConv2D(kernel_size=(3, 1),\n",
    "                        padding='same',\n",
    "                        use_bias=False)(x)\n",
    "    x = get_post(x)\n",
    "\n",
    "    x = Conv2D(ch_out,\n",
    "               kernel_size=(2, 1),\n",
    "               strides=(1, 2),\n",
    "               padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = get_post(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def Effnet(input_shape, nb_classes, include_top=True, weights=None, activation_top=None):\n",
    "    x_in = Input(shape=input_shape)\n",
    "\n",
    "    x = get_block(x_in, 32, 64)\n",
    "    x = get_block(x, 64, 128)\n",
    "    x = get_block(x, 128, 256)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        #x = Dense(256, activation=\"relu\")(x)\n",
    "        #x = Dense(256, activation=\"relu\")(x)\n",
    "        x = Dense(nb_classes, activation=activation_top)(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133a08c",
   "metadata": {
    "papermill": {
     "duration": 0.019921,
     "end_time": "2022-05-05T11:24:12.733650",
     "exception": false,
     "start_time": "2022-05-05T11:24:12.713729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utils Scripts\n",
    "\n",
    "Various utility scripts now like label-encoding for sin/cos output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9559e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:12.776804Z",
     "iopub.status.busy": "2022-05-05T11:24:12.776440Z",
     "iopub.status.idle": "2022-05-05T11:24:12.787499Z",
     "shell.execute_reply": "2022-05-05T11:24:12.786462Z"
    },
    "papermill": {
     "duration": 0.034664,
     "end_time": "2022-05-05T11:24:12.789590",
     "exception": false,
     "start_time": "2022-05-05T11:24:12.754926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def class_encoding(y_train, nb_classes):\n",
    "    ret = np.zeros((len(y_train), nb_classes))\n",
    "    for i, y in enumerate(y_train):\n",
    "        #print(i, y, int((y*10)))\n",
    "        ret[i, int((y*10))] = 1\n",
    "    return ret\n",
    "\n",
    "def class_decoding(y_train, nb_classes=100):\n",
    "    ret = np.zeros((len(y_train), 1))\n",
    "    for i, y in enumerate(y_train):\n",
    "        ret[i] = (np.argmax(y))/10\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5adcd",
   "metadata": {
    "papermill": {
     "duration": 0.020749,
     "end_time": "2022-05-05T11:24:12.890268",
     "exception": false,
     "start_time": "2022-05-05T11:24:12.869519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77172d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:12.933782Z",
     "iopub.status.busy": "2022-05-05T11:24:12.933232Z",
     "iopub.status.idle": "2022-05-05T11:24:13.696603Z",
     "shell.execute_reply": "2022-05-05T11:24:13.695641Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.788445,
     "end_time": "2022-05-05T11:24:13.699165",
     "exception": false,
     "start_time": "2022-05-05T11:24:12.910720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "def invert(imagem):\n",
    "    if (random.getrandbits(1)):\n",
    "        return (255)-imagem\n",
    "    else:\n",
    "        return imagem\n",
    "        \n",
    "\n",
    "Shift_Range = 0#2 # px\n",
    "Brightness_Range = [0.4,0.9]\n",
    "Rotation_Angle = 5\n",
    "ZoomRange_Out = 0#0.2\n",
    "ZoomRange_In = 0#0.1\n",
    "ShearRange= 2\n",
    "Channel_Shift=0#20\n",
    "Blur = 5\n",
    "\n",
    "def augmentation(x, y, Batch_Size = 32):\n",
    "    datagen = ImageDataGenerator(width_shift_range=Shift_Range, \n",
    "                             height_shift_range=Shift_Range,\n",
    "                             brightness_range=Brightness_Range,\n",
    "                             zoom_range=[1-ZoomRange_In, 1+ZoomRange_Out],\n",
    "                             rotation_range=Rotation_Angle,\n",
    "                             #channel_shift_range=Channel_Shift,\n",
    "                             fill_mode='nearest',\n",
    "                             shear_range=ShearRange\n",
    "                             ,preprocessing_function=invert\n",
    "                             ,dtype=float\n",
    "                             ,rescale=1./255)\n",
    "    return datagen.flow(x, y, batch_size=Batch_Size)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce3e47",
   "metadata": {
    "papermill": {
     "duration": 0.021701,
     "end_time": "2022-05-05T11:24:13.741855",
     "exception": false,
     "start_time": "2022-05-05T11:24:13.720154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6420fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:13.784618Z",
     "iopub.status.busy": "2022-05-05T11:24:13.784220Z",
     "iopub.status.idle": "2022-05-05T11:24:13.806876Z",
     "shell.execute_reply": "2022-05-05T11:24:13.805900Z"
    },
    "papermill": {
     "duration": 0.047243,
     "end_time": "2022-05-05T11:24:13.809343",
     "exception": false,
     "start_time": "2022-05-05T11:24:13.762100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_dataset(images, labels, columns=12, rows=5):\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    columns = 12\n",
    "    rows = 5\n",
    "\n",
    "    for i in range(1, columns*rows +1):\n",
    "        if (i>len(labels)):\n",
    "            break\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(labels[i-1])  # set title\n",
    "        if(images[i-1].shape[-1]==1):\n",
    "            plt.imshow((images[i-1]), aspect='auto', cmap='gray')\n",
    "        else:\n",
    "            plt.imshow((images[i-1]), aspect='auto')\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_dataset_it(data_iter, columns=12, rows=5):\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    columns = 12\n",
    "    rows = 5\n",
    "\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img, label = data_iter.next()\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(class_decoding(label[0].reshape(-1, nb_classes), nb_classes).reshape(-1)))  # set title\n",
    "        if(img[0].shape[-1]==1):\n",
    "            plt.imshow(img[0], aspect='auto', cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(img[0], aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "def plot_acc_loss(history, modelname=\"modelname\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(modelname)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    if \"loss\" in history.history:\n",
    "        ax1.plot(history.history['loss'])\n",
    "    if \"accuracy\" in history.history:\n",
    "        ax2.plot(history.history['accuracy'])\n",
    "    if \"val_loss\" in history.history:\n",
    "        ax1.plot(history.history['val_loss'])\n",
    "    if \"val_accuracy\" in history.history:\n",
    "        ax2.plot(history.history['val_accuracy'])\n",
    "    if \"student_loss\" in history.history:\n",
    "        ax1.plot(history.history['student_loss'])\n",
    "    if \"sparse_categorical_accuracy\" in history.history:\n",
    "        ax2.plot(history.history['sparse_categorical_accuracy'])\n",
    "    if \"val_sparse_categorical_accuracy\" in history.history:\n",
    "        ax2.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "    if \"student_accuracy\" in history.history:\n",
    "        ax2.plot(history.history['student_accuracy'])\n",
    "    if \"val_student_accuracy\" in history.history:\n",
    "        ax2.plot(history.history['val_student_accuracy'])\n",
    "    if \"distillation_loss\" in history.history:\n",
    "        ax1.plot(history.history['distillation_loss'])\n",
    "\n",
    "    ax1.set_title('model loss')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax1.legend(['train','eval'], loc='upper left')\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.92,1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_divergence(divergationset, title1, nb_classes):\n",
    "    fig = plt.figure(figsize=(40, 10))\n",
    "    fig.suptitle(title1)\n",
    "    plt.bar(np.arange (0, nb_classes/10, 0.1), divergationset, width=0.09, align='center')\n",
    "    plt.ylabel('count')\n",
    "    plt.xlabel('digit class')\n",
    "    plt.xticks(np.arange(0, nb_classes/10, 0.1))\n",
    "    return fig\n",
    "\n",
    "\n",
    "def confusion_matrix(predicted, y_test, nb_classes):\n",
    "    ytrue = pd.Series(np.argmax(class_encoding(y_test, nb_classes), axis = 1), name = 'actual')\n",
    "    ypred = pd.Series(np.argmax(class_encoding(predicted, nb_classes), axis = 1), name = 'pred')\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    return pd.crosstab(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9681f3",
   "metadata": {
    "papermill": {
     "duration": 0.020039,
     "end_time": "2022-05-05T11:24:13.849832",
     "exception": false,
     "start_time": "2022-05-05T11:24:13.829793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69963054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:13.892489Z",
     "iopub.status.busy": "2022-05-05T11:24:13.892138Z",
     "iopub.status.idle": "2022-05-05T11:24:14.012807Z",
     "shell.execute_reply": "2022-05-05T11:24:14.011477Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.145512,
     "end_time": "2022-05-05T11:24:14.015594",
     "exception": false,
     "start_time": "2022-05-05T11:24:13.870082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def tmnist_percentals(use_grayscale=True):\n",
    "    y_train = np.empty((0,1))\n",
    "    if (use_grayscale):\n",
    "        x_train = np.empty((0, 32, 20,1))\n",
    "    else:\n",
    "        x_train = np.empty((0, 32, 20,3))\n",
    "    \n",
    "    blacklist_url = \"datasets/font-blacklist.txt\"\n",
    "    blacklist_data = pd.read_csv(blacklist_url, index_col=False)\n",
    "    #print(blacklist_data.values.reshape(-1))\n",
    "    \n",
    "    for i in range(28):\n",
    "\n",
    "        dataset_url = \"datasets/TMNIST_PERCENTAL_\"+str((i+1)*1000)+\"_Data.csv\"\n",
    "        data = pd.read_csv(dataset_url, index_col=False)\n",
    "        data = data.drop(data[data['names'].isin(blacklist_data.values.reshape(-1))].index)\n",
    "        #print(data.head())\n",
    "        y_tmnist = data[['labels']]\n",
    "        #print(y_tmnist[y_tmnist.labels>10])\n",
    "        X = data.drop({'labels','names'},axis=1)\n",
    "\n",
    "        #print(data)\n",
    "        X_images = (255-(X.values.reshape(-1,28,28,1)))\n",
    "        X_images = tf.image.resize(X_images, (32,20))\n",
    "        X_images = np.array(X_images).reshape(-1,32,20,1)\n",
    "        X_images = X_images/255.\n",
    "            \n",
    "        if (use_grayscale!=True):\n",
    "            X_images = tf.image.grayscale_to_rgb(tf.convert_to_tensor(X_images))\n",
    "            \n",
    "\n",
    "        x_train = np.concatenate((X_images, x_train))\n",
    "        y_train = np.concatenate((y_tmnist.values, y_train))\n",
    "    #print(\">10\", y_train[y_train>10])\n",
    "    return shuffle(x_train,  y_train, n_samples=len(y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image \n",
    "\n",
    "def ziffer_data_files(input_dir='images'):\n",
    "    imgfiles = []\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if (file.endswith(\".jpg\") and not file.startswith(\"10_\")):\n",
    "                #print(root + \"/\" + file)\n",
    "                imgfiles.append(root + \"/\" + file)\n",
    "    return  imgfiles\n",
    "\n",
    "def ziffer_data(x_data, y_data, nb_classes, use_grayscale=True):\n",
    "\n",
    "    files = ziffer_data_files(\"images\")\n",
    "    files = files + ziffer_data_files(\"ziffer_raw\")\n",
    "    #print(\"Ziffer Imagecount: \", len(files))\n",
    "    y_data = np.array(y_data).reshape(-1,1)\n",
    "    if (use_grayscale):\n",
    "        x_data = np.array(x_data).reshape(-1,32,20,1)\n",
    "    else: \n",
    "        x_data = np.array(x_data).reshape(-1,32,20,3)\n",
    "\n",
    "    for aktfile in files:\n",
    "        base = os.path.basename(aktfile)\n",
    "        target = base[0:1]\n",
    "        if target == \"N\":\n",
    "            category = 10                # NaN does not work --> convert to 10\n",
    "\n",
    "        else:\n",
    "            category = int(target)\n",
    "        test_image = Image.open(aktfile).resize((20, 32))\n",
    "        if (use_grayscale):\n",
    "            test_image = test_image.convert('L')\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        test_image = test_image/255.\n",
    "            \n",
    "        #print(test_image.shape)\n",
    "        if (use_grayscale):\n",
    "            test_image = test_image.reshape(1,32,20,1)\n",
    "        else:\n",
    "            test_image = test_image.reshape(1,32,20,3)\n",
    "\n",
    "        # ignore the category 10\n",
    "        if ( category<10):\n",
    "            x_data = np.vstack((x_data, test_image))\n",
    "            y_data = np.vstack((y_data, [category]))\n",
    "    print(\"Ziffer data count: \", len(y_data))   \n",
    "    return shuffle(x_data, y_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b907a8",
   "metadata": {
    "papermill": {
     "duration": 0.021993,
     "end_time": "2022-05-05T11:24:14.058821",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.036828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a266a8c9",
   "metadata": {
    "papermill": {
     "duration": 0.020231,
     "end_time": "2022-05-05T11:24:14.149547",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.129316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59432adc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:14.192798Z",
     "iopub.status.busy": "2022-05-05T11:24:14.192455Z",
     "iopub.status.idle": "2022-05-05T11:25:35.224756Z",
     "shell.execute_reply": "2022-05-05T11:25:35.223824Z"
    },
    "papermill": {
     "duration": 81.057792,
     "end_time": "2022-05-05T11:25:35.227814",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.170022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xz_data, yz_data = ziffer_data([],[], 10, use_grayscale=use_grayscale)\n",
    "\n",
    "x_data, y_data = tmnist_percentals(use_grayscale=use_grayscale)\n",
    "x_data = np.concatenate((x_data, xz_data))\n",
    "y_data = np.concatenate((y_data, yz_data))\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "input_shape=x_data[0].shape\n",
    "print(f\"dataset x_data-size={len(x_data)}\")\n",
    "plot_dataset(x_data, y_data)\n",
    "\n",
    "y_data = class_encoding(y_data, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f9cb5",
   "metadata": {
    "papermill": {
     "duration": 0.023702,
     "end_time": "2022-05-05T11:25:35.276412",
     "exception": false,
     "start_time": "2022-05-05T11:25:35.252710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Augmentation\n",
    "\n",
    "So it looks more like real meter digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502b913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:25:35.326369Z",
     "iopub.status.busy": "2022-05-05T11:25:35.326054Z",
     "iopub.status.idle": "2022-05-05T11:25:44.010058Z",
     "shell.execute_reply": "2022-05-05T11:25:44.009397Z"
    },
    "papermill": {
     "duration": 8.713367,
     "end_time": "2022-05-05T11:25:44.014279",
     "exception": false,
     "start_time": "2022-05-05T11:25:35.300912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split train and validation data \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "\n",
    "train_iterator = augmentation(x_train, y_train)\n",
    "validation_iterator = augmentation(x_test, y_test)\n",
    "\n",
    "plot_dataset_it(train_iterator)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc363c6c",
   "metadata": {
    "papermill": {
     "duration": 0.02918,
     "end_time": "2022-05-05T11:25:44.073414",
     "exception": false,
     "start_time": "2022-05-05T11:25:44.044234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The Model\n",
    "\n",
    "Is an small EfficientNet like model with 3 Dense layer at top. The last layer uses **tanh** as activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9035321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:25:44.134798Z",
     "iopub.status.busy": "2022-05-05T11:25:44.134200Z",
     "iopub.status.idle": "2022-05-05T11:25:44.462117Z",
     "shell.execute_reply": "2022-05-05T11:25:44.461207Z"
    },
    "papermill": {
     "duration": 0.361475,
     "end_time": "2022-05-05T11:25:44.464621",
     "exception": false,
     "start_time": "2022-05-05T11:25:44.103146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = Effnet(input_shape, nb_classes, activation_top=None)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              optimizer=\"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383fdaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:25:44.524942Z",
     "iopub.status.busy": "2022-05-05T11:25:44.524378Z",
     "iopub.status.idle": "2022-05-05T19:24:32.253300Z",
     "shell.execute_reply": "2022-05-05T19:24:32.251187Z"
    },
    "papermill": {
     "duration": 28727.762738,
     "end_time": "2022-05-05T19:24:32.256769",
     "exception": false,
     "start_time": "2022-05-05T11:25:44.494031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_iterator, \n",
    "                validation_data=validation_iterator, \n",
    "                batch_size=Batch_Size, \n",
    "                epochs = 50,\n",
    "                verbose=1)\n",
    "\n",
    "plot_acc_loss(history, \"Trainingsresults\")\n",
    "\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71946b7a",
   "metadata": {
    "papermill": {
     "duration": 0.068785,
     "end_time": "2022-05-05T19:24:32.394252",
     "exception": false,
     "start_time": "2022-05-05T19:24:32.325467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Verfify the training\n",
    "\n",
    "Now a few (5000) images from validation set will be used to evaluate the model.\n",
    "\n",
    "All the first (max 30) false predicted images will be shown.\n",
    "\n",
    "If all fine the predictions will be shown in a diagram and it should be a sinus and cosinus wave. The glitches are the false predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f7036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T19:24:32.536948Z",
     "iopub.status.busy": "2022-05-05T19:24:32.535329Z",
     "iopub.status.idle": "2022-05-05T19:30:01.099257Z",
     "shell.execute_reply": "2022-05-05T19:30:01.098006Z"
    },
    "papermill": {
     "duration": 328.639219,
     "end_time": "2022-05-05T19:30:01.102847",
     "exception": false,
     "start_time": "2022-05-05T19:24:32.463628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "res = []\n",
    "stat_Anz = []\n",
    "stat_Abweichung = []\n",
    "false_img = []\n",
    "false_label = []\n",
    "test_count = 5000\n",
    "\n",
    "for i in range(100):\n",
    "    stat_Anz.append(0)\n",
    "    stat_Abweichung.append(0)\n",
    "\n",
    "for x_test, y_test in validation_iterator:\n",
    "    if (test_count<0):\n",
    "        break\n",
    "    test_count = test_count - Batch_Size\n",
    "           \n",
    "    for (x, y) in zip(x_test, y_test):\n",
    "            \n",
    "        target = class_decoding([y])\n",
    "        classes = model.predict(np.expand_dims(x.reshape(input_shape), axis=0))\n",
    "        \n",
    "        \n",
    "        out_target = class_decoding(classes)[0]\n",
    "\n",
    "                       \n",
    "        if target != out_target:\n",
    "            lbl_text = \"Expected: \" + str(target) + \"\\n Predicted: \" + str(out_target)\n",
    "            print(\"Exp: \" + str(target) + \" Pred: \" + str(out_target))\n",
    "            false_img.append(x)\n",
    "            false_label.append(lbl_text)\n",
    "    \n",
    "for i in range(100):\n",
    "    if (stat_Anz[i] != 0):\n",
    "        stat_Abweichung[i] = stat_Abweichung[i] / stat_Anz[i]\n",
    "\n",
    "res = np.asarray(res)\n",
    "res_step_1 = res\n",
    "print(f\"{len(false_label)} false predicted\")\n",
    "plot_dataset(np.array(false_img), false_label, columns=11, rows=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "res = []\n",
    "stat_Abweichung = np.zeros(nb_classes)\n",
    "false_img = []\n",
    "false_label = []\n",
    "max_delta = 0.11\n",
    "\n",
    "def isclose(a, b, delta):\n",
    "    return min(abs(a-b),abs(a-(10-b)))<=delta\n",
    "\n",
    "\n",
    "for x, y in zip(xz_data, yz_data):\n",
    "\n",
    "    target = y\n",
    "    classes = model.predict(np.expand_dims(x.reshape(input_shape), axis=0))\n",
    "    out_target = class_decoding(classes)[0]\n",
    "    res.append(out_target)\n",
    "                   \n",
    "    if not isclose(target, out_target, max_delta) :\n",
    "        lbl_text = \"Expected: \" + str(target) + \"\\n Predicted: \" + str(out_target)\n",
    "        #print(\"Exp: \" + str(target) + \" Pred: \" + str(out_target))\n",
    "        false_img.append(x)\n",
    "        false_label.append(lbl_text)\n",
    "        stat_Abweichung[int(abs(target-out_target)*10)] = stat_Abweichung[int(abs(target-out_target)*10)]+1\n",
    "\n",
    "res = np.asarray(res)\n",
    "res_step_1 = res\n",
    "print(f\"Tested images: {len(yz_data)}. {len(false_label)} false predicted. Accuracy is: {1-len(false_label)/len(yz_data)}\")\n",
    "plot_divergence(stat_Abweichung, \"Divergation of false predicted\", nb_classes)\n",
    "print(confusion_matrix(res, yz_data, nb_classes))\n",
    "plot_dataset(np.array(false_img), false_label, columns=11, rows=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29168.886987,
   "end_time": "2022-05-05T19:30:04.260551",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-05T11:23:55.373564",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
