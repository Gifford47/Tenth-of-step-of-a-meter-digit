{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ed381c",
   "metadata": {
    "papermill": {
     "duration": 0.022496,
     "end_time": "2022-05-05T11:24:06.118995",
     "exception": false,
     "start_time": "2022-05-05T11:24:06.096499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The Resnet50 model\n",
    "\n",
    "Using resnet50 in comparisation to effnet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d83ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:14.101280Z",
     "iopub.status.busy": "2022-05-05T11:24:14.100810Z",
     "iopub.status.idle": "2022-05-05T11:24:14.106190Z",
     "shell.execute_reply": "2022-05-05T11:24:14.105470Z"
    },
    "papermill": {
     "duration": 0.02918,
     "end_time": "2022-05-05T11:24:14.108133",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.078953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "Training_Percentage = 0.2           \n",
    "Epoch_Anz = 80\n",
    "nb_classes = 100                     # move to 1. step\n",
    "#input_shape = (32, 20,1)            # will be calculated\n",
    "Batch_Size = 32\n",
    "use_grayscale = True                # grayscale or rgb\n",
    "model_filename = \"resnet.h5\"\n",
    "\n",
    "############################ augmentation ###############################\n",
    "\n",
    "Shift_Range = 1 # px\n",
    "Brightness_Range = [0.4,0.9]\n",
    "Rotation_Angle = 3\n",
    "ZoomRange_Out = 0.1\n",
    "ZoomRange_In = 0.1\n",
    "ShearRange= 2\n",
    "Channel_Shift=0.2\n",
    "\n",
    "########################### data paths ##################################\n",
    "\n",
    "\n",
    "tmnist_dir = 'datasets'\n",
    "ziffer_dir = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "### for kaggle the input paths must be changed\n",
    "if (os.path.exists('/kaggle/input/between2numbers/')):\n",
    "    package_paths = [\n",
    "        '/kaggle/input/between2numbers/',\n",
    "    ]\n",
    "\n",
    "    for pth in package_paths:\n",
    "        sys.path.append(pth)\n",
    "\n",
    "    tmnist_dir = '/kaggle/input/between2numbers/datasets'\n",
    "    ziffer_dir = '/kaggle/input/between2numbers/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b907a8",
   "metadata": {
    "papermill": {
     "duration": 0.021993,
     "end_time": "2022-05-05T11:24:14.058821",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.036828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a266a8c9",
   "metadata": {
    "papermill": {
     "duration": 0.020231,
     "end_time": "2022-05-05T11:24:14.149547",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.129316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data\n",
    "\n",
    "Like the distillation network meter digits will be trained with font builded images.\n",
    "\n",
    "The meter digits are all 0-9 ziffer_raw + my own data 0-9. \n",
    "At now no images used between two digits. Many images from 0-9 are +/- 0.2 devergent and not correctly labeled. (See the last result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59432adc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:24:14.192798Z",
     "iopub.status.busy": "2022-05-05T11:24:14.192455Z",
     "iopub.status.idle": "2022-05-05T11:25:35.224756Z",
     "shell.execute_reply": "2022-05-05T11:25:35.223824Z"
    },
    "papermill": {
     "duration": 81.057792,
     "end_time": "2022-05-05T11:25:35.227814",
     "exception": false,
     "start_time": "2022-05-05T11:24:14.170022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from b2n.data.ziffer import ziffer_data\n",
    "from b2n.data.tmnist import tmnist_percentals\n",
    "from sklearn.utils import shuffle\n",
    "from b2n.plotfunctions import plot_dataset\n",
    "from b2n.encodings.class_encoding import class_encoding\n",
    "import numpy as np\n",
    "\n",
    "xz_data, yz_data, fz_data = ziffer_data(ziffer_dir, use_grayscale=use_grayscale)\n",
    "\n",
    "\n",
    "x_data, y_data = tmnist_percentals(tmnist_dir, use_grayscale=use_grayscale)\n",
    "x_data = np.concatenate((x_data, xz_data))\n",
    "y_data = np.concatenate((y_data, yz_data))\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "input_shape=x_data[0].shape\n",
    "print(f\"dataset x_data-size={len(x_data)}\")\n",
    "plot_dataset(x_data, y_data)\n",
    "\n",
    "y_data = class_encoding(y_data, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f9cb5",
   "metadata": {
    "papermill": {
     "duration": 0.023702,
     "end_time": "2022-05-05T11:25:35.276412",
     "exception": false,
     "start_time": "2022-05-05T11:25:35.252710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Augmentation\n",
    "See augementation above for augmentation values.\n",
    "Standard augmentation of image generator is used plus inverting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502b913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:25:35.326369Z",
     "iopub.status.busy": "2022-05-05T11:25:35.326054Z",
     "iopub.status.idle": "2022-05-05T11:25:44.010058Z",
     "shell.execute_reply": "2022-05-05T11:25:44.009397Z"
    },
    "papermill": {
     "duration": 8.713367,
     "end_time": "2022-05-05T11:25:44.014279",
     "exception": false,
     "start_time": "2022-05-05T11:25:35.300912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from b2n.augmentation.generator import augmentation\n",
    "from b2n.plotfunctions import plot_dataset_it\n",
    "\n",
    "# Split train and validation data \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "\n",
    "train_iterator = augmentation(x_train, y_train)\n",
    "validation_iterator = augmentation(x_test, y_test)\n",
    "\n",
    "plot_dataset_it(train_iterator)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc363c6c",
   "metadata": {
    "papermill": {
     "duration": 0.02918,
     "end_time": "2022-05-05T11:25:44.073414",
     "exception": false,
     "start_time": "2022-05-05T11:25:44.044234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The Model\n",
    "\n",
    "Is an small EfficientNet like model with a dense output of 100 at top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9035321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:25:44.134798Z",
     "iopub.status.busy": "2022-05-05T11:25:44.134200Z",
     "iopub.status.idle": "2022-05-05T11:25:44.462117Z",
     "shell.execute_reply": "2022-05-05T11:25:44.461207Z"
    },
    "papermill": {
     "duration": 0.361475,
     "end_time": "2022-05-05T11:25:44.464621",
     "exception": false,
     "start_time": "2022-05-05T11:25:44.103146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_tensor = Input(shape=input_shape)\n",
    "base_model = ResNet50(input_tensor=input_tensor, classes=nb_classes, weights=None, include_top=True)\n",
    "x = base_model.output\n",
    "#x = Dense(1024, activation='relu')(x)\n",
    "#predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# Model to be trained\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), \n",
    "              optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383fdaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T11:25:44.524942Z",
     "iopub.status.busy": "2022-05-05T11:25:44.524378Z",
     "iopub.status.idle": "2022-05-05T19:24:32.253300Z",
     "shell.execute_reply": "2022-05-05T19:24:32.251187Z"
    },
    "papermill": {
     "duration": 28727.762738,
     "end_time": "2022-05-05T19:24:32.256769",
     "exception": false,
     "start_time": "2022-05-05T11:25:44.494031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from b2n.plotfunctions import plot_acc_loss\n",
    "\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.96 ** x, verbose=0)\n",
    "\n",
    "history = model.fit(train_iterator, \n",
    "                validation_data=validation_iterator, \n",
    "                batch_size=Batch_Size, \n",
    "                epochs = Epoch_Anz,\n",
    "                callbacks=[annealer],\n",
    "                verbose=2)\n",
    "\n",
    "plot_acc_loss(history, \"Trainingsresults\")\n",
    "\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71946b7a",
   "metadata": {
    "papermill": {
     "duration": 0.068785,
     "end_time": "2022-05-05T19:24:32.394252",
     "exception": false,
     "start_time": "2022-05-05T19:24:32.325467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Verfify the training\n",
    "\n",
    "Now a few (5000) images from validation set will be used to evaluate the model.\n",
    "\n",
    "All the first (max 30) false predicted images will be shown.\n",
    "\n",
    "If all fine the predictions will be shown in a diagram and it should be a sinus and cosinus wave. The glitches are the false predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f7036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T19:24:32.536948Z",
     "iopub.status.busy": "2022-05-05T19:24:32.535329Z",
     "iopub.status.idle": "2022-05-05T19:30:01.099257Z",
     "shell.execute_reply": "2022-05-05T19:30:01.098006Z"
    },
    "papermill": {
     "duration": 328.639219,
     "end_time": "2022-05-05T19:30:01.102847",
     "exception": false,
     "start_time": "2022-05-05T19:24:32.463628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from b2n.encodings.class_encoding import class_decoding\n",
    "from b2n.plotfunctions import plot_divergence, plot_dataset\n",
    "\n",
    "res = []\n",
    "stat_Anz = []\n",
    "stat_Abweichung = []\n",
    "false_img = []\n",
    "false_label = []\n",
    "test_count = 5000\n",
    "\n",
    "for i in range(100):\n",
    "    stat_Anz.append(0)\n",
    "    stat_Abweichung.append(0)\n",
    "\n",
    "for x_test, y_test in validation_iterator:\n",
    "    if (test_count<0):\n",
    "        break\n",
    "    test_count = test_count - Batch_Size\n",
    "           \n",
    "    for (x, y) in zip(x_test, y_test):\n",
    "            \n",
    "        target = class_decoding([y])\n",
    "        classes = model.predict(np.expand_dims(x.reshape(input_shape), axis=0))\n",
    "        \n",
    "        \n",
    "        out_target = class_decoding(classes)[0]\n",
    "\n",
    "                       \n",
    "        if target != out_target:\n",
    "            lbl_text = \"Expected: \" + str(target) + \"\\n Predicted: \" + str(out_target)\n",
    "            print(\"Exp: \" + str(target) + \" Pred: \" + str(out_target))\n",
    "            false_img.append(x)\n",
    "            false_label.append(lbl_text)\n",
    "    \n",
    "for i in range(100):\n",
    "    if (stat_Anz[i] != 0):\n",
    "        stat_Abweichung[i] = stat_Abweichung[i] / stat_Anz[i]\n",
    "\n",
    "res = np.asarray(res)\n",
    "res_step_1 = res\n",
    "print(f\"{len(false_label)} false predicted\")\n",
    "plot_dataset(np.array(false_img), false_label, columns=11, rows=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d832bc7",
   "metadata": {},
   "source": [
    "### Ziffer images\n",
    "\n",
    "The model is build for predicting meter digit images (Ziffer). So we test *all* meter digit images of the dataset (not only the validation set)\n",
    "\n",
    "max_delta can set a value, that ignored convergence +/- of the value and accept it as predicted correctly.\n",
    "\n",
    "Because of the meter digit dataset (only 0.0, 1.0, ... 9.0) We have no real answer how good the images between two digits are predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from b2n.encodings.class_encoding import class_decoding\n",
    "from b2n.plotfunctions import plot_divergence, plot_dataset\n",
    "\n",
    "res = []\n",
    "stat_Abweichung = np.zeros(nb_classes)\n",
    "false_img = []\n",
    "false_label = []\n",
    "max_delta = 0.11\n",
    "\n",
    "def isclose(a, b, delta):\n",
    "    return min(abs(a-b),abs(a-(10-b)))<=delta\n",
    "\n",
    "\n",
    "for x, y, filename in zip(xz_data, yz_data, fz_data):\n",
    "\n",
    "    target = y\n",
    "    classes = model.predict(np.expand_dims(x.reshape(input_shape), axis=0))\n",
    "    out_target = class_decoding(classes)[0]\n",
    "    res.append(out_target)\n",
    "                   \n",
    "    if not isclose(target, out_target, max_delta) :\n",
    "        lbl_text = \"Expected: \" + str(target) + \"\\n Predicted: \" + str(out_target) + \"\\n\" + filename[0][:-4]\n",
    "        #print(\"Exp: \" + str(target) + \" Pred: \" + str(out_target))\n",
    "        false_img.append(x)\n",
    "        false_label.append(lbl_text)\n",
    "        stat_Abweichung[int(abs(target-out_target)*10)] = stat_Abweichung[int(abs(target-out_target)*10)]+1\n",
    "        # move image to failure_dir \n",
    "        #move_to_failure_dir(filename[0])\n",
    "\n",
    "\n",
    "print(f\"Tested images: {len(yz_data)}. {len(false_label)} false predicted. Accuracy is: {1-len(false_label)/len(yz_data)}\")\n",
    "plot_divergence(stat_Abweichung, \"Divergation of false predicted\", nb_classes)\n",
    "#print(confusion_matrix(np.asarray(res), yz_data, nb_classes))\n",
    "plot_dataset(np.array(false_img), false_label, columns=8, rows=5, figsize=(18,16))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29168.886987,
   "end_time": "2022-05-05T19:30:04.260551",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-05T11:23:55.373564",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
