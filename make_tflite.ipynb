{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "########### Basic Parameters for Running: ################################\n",
    "\n",
    "DateNow = datetime.today().strftime('%Y%m%d')\n",
    "TimeNow = datetime.today().strftime('%H%M%S')\n",
    "    \n",
    "TFliteNamingAndVersion = \"effnet100-\" + DateNow + \"-\" + TimeNow     # Used for tflite Filename\n",
    "#TFliteNamingAndVersion = \"effnet\"     # Used for tflite Filename\n",
    "Load_Model = \"eff100-rgb.h5\"  \n",
    "ziffer_data_url=\"images\"\n",
    "output_dir=\".\"\n",
    "use_grayscale = False\n",
    "nb_classes = 100\n",
    "##########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ziffer data count:  8340\n",
      "(8340, 100)\n",
      "(6672, 100) (1668, 100)\n",
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 07:32:07.103223: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-01 07:32:07.103357: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-06-01 07:32:07.530468: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-01 07:32:07.630525: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning\n",
      "Baseline test accuracy: 0.8183453679084778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:212: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  mask = self.add_variable(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:219: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  threshold = self.add_variable(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:233: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.pruning_step = self.add_variable(\n",
      "2022-06-01 07:32:11.983590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/188 [..............................] - ETA: 9s - loss: 2.4455 - accuracy: 0.5875 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0387s vs `on_train_batch_end` time: 0.1662s). Check your callbacks.\n",
      "188/188 [==============================] - ETA: 0s - loss: 1.0310 - accuracy: 0.7422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 07:32:22.126691: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 14s 46ms/step - loss: 1.0310 - accuracy: 0.7422 - val_loss: 0.5265 - val_accuracy: 0.8249\n",
      "Baseline test accuracy: 0.8183453679084778\n",
      "Pruned test accuracy: 0.8513189554214478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 07:32:24.651658: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpp_xofgof/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 07:32:35.330152: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-06-01 07:32:35.330174: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-06-01 07:32:35.330562: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpp_xofgof\n",
      "2022-06-01 07:32:35.334414: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-06-01 07:32:35.334436: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpp_xofgof\n",
      "2022-06-01 07:32:35.347464: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-01 07:32:35.405479: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpp_xofgof\n",
      "2022-06-01 07:32:35.428616: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 98054 microseconds.\n",
      "2022-06-01 07:32:35.472612: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpyqiir6vc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpyqiir6vc/assets\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-06-01 07:32:47.053276: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-06-01 07:32:47.053290: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-06-01 07:32:47.053366: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpyqiir6vc\n",
      "2022-06-01 07:32:47.056627: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-06-01 07:32:47.056637: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpyqiir6vc\n",
      "2022-06-01 07:32:47.068426: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-01 07:32:47.122006: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/07/sj9pw71n205_354358yc8scm0000gn/T/tmpyqiir6vc\n",
      "2022-06-01 07:32:47.144482: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 91115 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "468152"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from b2n.models.prune_quantize import prune, quantization_default\n",
    "from b2n.data.ziffer import ziffer_data\n",
    "from b2n.encodings.class_encoding import class_encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "xz_data, yz_data, fz_data = ziffer_data(ziffer_data_url)\n",
    "x_data, y_data = shuffle(xz_data, yz_data)\n",
    "y_data = class_encoding(y_data, nb_classes)\n",
    "print(y_data.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "model = keras.models.load_model(Load_Model)\n",
    "\n",
    "# prune the model\n",
    "model_pruned = prune(model=model,\n",
    "        x_train=x_train, \n",
    "        y_train=y_train,\n",
    "        x_test=x_test, \n",
    "        y_test=y_test)\n",
    "\n",
    "# quanitize and save the model\n",
    "tflite_model = quantization_default(model=model_pruned, \n",
    "                            x_train=x_test)\n",
    "# save the model\n",
    "filename=TFliteNamingAndVersion + \"-q.tflite\"                                                     \n",
    "open( filename, \"wb\").write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
